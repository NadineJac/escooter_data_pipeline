{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "490dd4ed",
   "metadata": {},
   "source": [
    "# Scape info on cities from Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed994dcf",
   "metadata": {},
   "source": [
    "Use english city names to obtain info from Wikipedia-pages:\n",
    "* Country\n",
    "* Popilation\n",
    "* Coordinates (latitude, longitude)\n",
    "\n",
    "Store in two seperate dataframes to export to MySQL\n",
    "\n",
    "`cities_df`\n",
    "* city_name (str)\n",
    "* country (str)\n",
    "* country_code (str)\n",
    "* latitude (float)\n",
    "* longitude (float)\n",
    "\n",
    "`pop_df`\n",
    "* city_name (str)\n",
    "* population (int)\n",
    "* measurement_date (string)\n",
    "* retrieval_date (date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13db605",
   "metadata": {},
   "source": [
    "Please ensure you have set up the corresponding tables with `sql/create_database_data_pipeline_example.sql`.\n",
    "\n",
    "Save you MySQL password in `python/key.env` as `MYSQL_KEY` (or provide you password by other means) and open your MySQL workbench."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb31ab3",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becd42eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlalchemy\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import keys #SQL connection settings and API keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba14893f",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786ac20c",
   "metadata": {},
   "source": [
    "## City info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34377fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCityInfoWiki(cities):\n",
    "    '''\n",
    "    Compile info on Cities from Wikipedia:\n",
    "    Country, Latitude, Longitude, Pupulation and date when population was assessed\n",
    "    INPUT: list of city names in English\n",
    "    OUTPUT:pandas data frame with columns:\n",
    "        city (str)\n",
    "        country (str)\n",
    "        latitude (float)\n",
    "        longitude (float)\n",
    "\n",
    "    To-do:\n",
    "    - add error if wiki page not found\n",
    "    '''\n",
    "    country = []\n",
    "    country_code = []\n",
    "    latitude = []\n",
    "    longitude = []\n",
    "\n",
    "    def convert_coordinates_degree2dec(coord):\n",
    "        \"\"\"Convert coordinates from DMS (e.g., '13°24′18″E', '13°24′E', or '13°E') to decimal degrees.\"\"\"\n",
    "        import re\n",
    "        import math\n",
    "\n",
    "        # Regex that allows optional minutes (′) and seconds (″)\n",
    "        match = re.match(\n",
    "            r\"^\\s*(\\d+)°(?:\\s*(\\d+)′)?(?:\\s*(\\d+)″)?\\s*([NSEW])\\s*$\",\n",
    "            coord\n",
    "        )\n",
    "\n",
    "        if match:\n",
    "            degrees, minutes, seconds, direction = match.groups()\n",
    "\n",
    "            # Default missing parts to 0\n",
    "            minutes = float(minutes) if minutes else 0.0\n",
    "            seconds = float(seconds) if seconds else 0.0\n",
    "\n",
    "            # Convert to decimal degrees\n",
    "            decimal = float(degrees) + minutes/60 + seconds/3600\n",
    "\n",
    "            # West/South are negative\n",
    "            if direction in ['W', 'S']:\n",
    "                decimal = -decimal\n",
    "        else:\n",
    "            decimal = float('nan')  # Return NaN for invalid format\n",
    "            print(f\"Invalid coordinate format: {coord}\")\n",
    "\n",
    "        return decimal\n",
    "\n",
    "\n",
    "    for city in cities:\n",
    "        url = \"https://en.wikipedia.org/wiki/\" + city.replace(\" \", \"_\")\n",
    "        headers = {'User-Agent': 'Chrome/134.0.0.0'}\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup_city = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Country\n",
    "        country_name = soup_city.find(\"th\", string=\"Country\").find_next(\"td\").get_text()\n",
    "        country.append(country_name)\n",
    "        country_code.append(country_name.upper()[0:3])\n",
    "\n",
    "        # Location\n",
    "        latitude.append(convert_coordinates_degree2dec(soup_city.find(class_='latitude').get_text()))\n",
    "        longitude.append(convert_coordinates_degree2dec(soup_city.find(class_='longitude').get_text()))\n",
    "    \n",
    "    cities_df = pd.DataFrame({\n",
    "        'city_name': cities, \n",
    "        'country':country, \n",
    "        'country_code':country_code, \n",
    "        'latitude':latitude, \n",
    "        'longitude': longitude\n",
    "        })\n",
    "    return cities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6a09b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cities = ['Berlin', 'Hamburg', 'Munich'] # if you did not define cities in keys.py\n",
    "cities_df = getCityInfoWiki(keys.CITIES)\n",
    "cities_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec93c2e",
   "metadata": {},
   "source": [
    "## Population Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac0c76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCityPopWiki(cities):\n",
    "    '''\n",
    "    Compile info on Cities from Wikipedia:\n",
    "    Country, Latitude, Longitude, Pupulation and date when population was assessed\n",
    "    INPUT: list of city names in English\n",
    "    OUTPUT:pandas data frame with columns:\n",
    "        city (str)\n",
    "        population (int)\n",
    "        measurement_date (string)\n",
    "        retrieval_date (date)\n",
    "\n",
    "    To-do:\n",
    "    - add error if wiki page not found\n",
    "    '''\n",
    "\n",
    "    population = []\n",
    "    measurement_date = []\n",
    "    retrieval_date = []\n",
    "\n",
    "    for city in cities:\n",
    "        url = \"https://en.wikipedia.org/wiki/\" + city.replace(\" \", \"_\")\n",
    "        headers = {'User-Agent': 'Chrome/134.0.0.0'}\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup_city = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Population\n",
    "        pop = soup_city.find(string=\"Population\").find_next('td').get_text()\n",
    "        population.append(int(pop.replace(\",\", \"\")))\n",
    "        date = soup_city.find(string=\"Population\").find_next('div').get_text()\n",
    "        measurement_date.append(re.search(r'\\((.*?)\\)', date).group(1))\n",
    "        retrieval_date.append(datetime.today().strftime('%Y-%m-%d'))\n",
    "\n",
    "    cities_df = pd.DataFrame(\n",
    "        {'city_name': cities, \n",
    "         'population':population, \n",
    "         'measurement_date':measurement_date, \n",
    "         'retrieval_date':retrieval_date})\n",
    "    \n",
    "    return cities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639e078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df = getCityPopWiki(cities)\n",
    "pop_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5112f2cf",
   "metadata": {},
   "source": [
    "## Airports info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cb30ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_airports(cities_df):\n",
    "  # API headers\n",
    "  load_dotenv('keys.env')\n",
    "  API_KEY = os.getenv(\"AERODATABOX_KEY\")\n",
    "  headers = {\n",
    "      \"X-RapidAPI-Key\": API_KEY,\n",
    "      \"X-RapidAPI-Host\": \"aerodatabox.p.rapidapi.com\"\n",
    "  }\n",
    "\n",
    "  # DataFrame to store results\n",
    "  all_airports = []\n",
    "  for _, city in cities_df.iterrows():\n",
    "    lat = city[\"latitude\"]\n",
    "    lon = city[\"longitude\"]\n",
    "\n",
    "    # Construct the URL with the latitude and longitude\n",
    "    url = f\"https://aerodatabox.p.rapidapi.com/airports/search/location/\"\n",
    "    querystring = {\"lat\":lat, \"lon\":lon,\"radiusKm\":\"50\",\"limit\":\"10\",\"withFlightInfoOnly\":\"true\"}\n",
    "\n",
    "    # Make the API request\n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "      data = response.json()\n",
    "      airports = pd.json_normalize(data.get('items', []))\n",
    "      airports['city_id'] =city[\"city_id\"]\n",
    "      all_airports.append(airports)\n",
    "\n",
    "  return pd.concat(all_airports, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254a40ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_airports = get_airports(cities_from_sql)\n",
    "airports_df = all_airports[['icao', 'name', 'city_id']]\n",
    "airports_df = airports_df.rename(columns={\"icao\": \"icao_code\", \"name\": \"airport_name\"})\n",
    "airports_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1f8c73",
   "metadata": {},
   "source": [
    "# Send data to SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2ce7c4",
   "metadata": {},
   "source": [
    "Please ensure you have set up the corresponding tables with `sql/create_database_data_pipeline_example.sql`.\n",
    "\n",
    "Save you MySQL password in `python/key.env` as `MYSQL_KEY` (or provide you password by other means) and open your MySQL workbench."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881fb037",
   "metadata": {},
   "source": [
    "### Provide info to connect to MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8fd930",
   "metadata": {},
   "outputs": [],
   "source": [
    "password = keys.WBS_MYSQL_DB\n",
    "schema = \"data_pipeline_example\"\n",
    "host = keys.HOST\n",
    "user = keys.USER\n",
    "port = keys.PORT\n",
    "\n",
    "connection_string = f'mysql+pymysql://{user}:{password}@{host}:{port}/{schema}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fe8599",
   "metadata": {},
   "source": [
    "### Send city data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46136e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_df.to_sql('cities',\n",
    "                  if_exists='append',\n",
    "                  con=connection_string,\n",
    "                  index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9419ae",
   "metadata": {},
   "source": [
    "### Send population data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59849c77",
   "metadata": {},
   "source": [
    "Retrieve city data first and merge with population data frage to get the city_id. Then send population data to MySQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e73dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_from_sql = pd.read_sql(\"cities\", con=connection_string)\n",
    "\n",
    "pop_merged_df = pop_df.merge(cities_from_sql[['city_id','city_name']],\n",
    "                      on = \"city_name\",\n",
    "                      how=\"left\")\n",
    "pop_merged_df = pop_merged_df.drop(columns=[\"city_name\"])\n",
    "pop_merged_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fa380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_merged_df.to_sql('population',\n",
    "                if_exists='append',\n",
    "                con=connection_string,\n",
    "                index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2defb72a",
   "metadata": {},
   "source": [
    "## Send airport data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68e1c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_df.to_sql(\n",
    "        'cities_airports',\n",
    "        if_exists='append',\n",
    "        con=connection_string,\n",
    "        index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
